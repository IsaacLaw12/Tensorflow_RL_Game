{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for CS445, Spring, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isaac Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I am going to create a program that uses Reinforcement Learning to play a simple video game. I developed a simple game in which a sheepdog tries to push the sheep into their pen. The mechanics of the game are the equivalent of particles that repel each other; the sheep flee away from the dog.  To successfully play the game the model will need to learn how to position the player behind the sheep and push them towards the pen.  The model will also need to learn how to handle map elements such as corners and walls.  Corners are a special case because the sheep can not be pushed out of the corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.5\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from game_assets import GameMap\n",
    "game_map = GameMap('map_rl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/isaac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_state = tf.placeholder(shape=[None, 6], dtype=tf.float32)\n",
    "\n",
    "hidden_one = slim.fully_connected(input_state, 2, activation_fn=tf.nn.tanh)\n",
    "#hidden_two = slim.fully_connected(hidden_one, 2, activation_fn=tf.nn.tanh)\n",
    "\n",
    "q_est = slim.fully_connected(hidden_one, 1, activation_fn=None)\n",
    "print_q_est = tf.print(q_est)\n",
    "q_estn = tf.cast(q_est, dtype=tf.float32, name=\"Scalar q_est\")\n",
    "print_q_estn = tf.print(q_estn)\n",
    "\n",
    "def action_picker(sess, state, epsilon):\n",
    "    '''\n",
    "    1 represents standing still.\n",
    "    2-5 are N, E, S, W\n",
    "    where N = [0, -1]\n",
    "    '''    \n",
    "    actions = [i for i in range(1, 6)]\n",
    "    \n",
    "    if True:# np.random.uniform() < epsilon:\n",
    "        action = np.random.choice(actions)\n",
    "    else:\n",
    "        random_actions = random.sample(actions, len(actions))\n",
    "        Qs = [NNETQ.use(np.array([[state, a]])) for a in random_actions]\n",
    "        ai = np.argmax(Qs)\n",
    "        action = random_actions[ai]\n",
    "    Q = sess.run([q_estn], feed_dict={input_state: state.reshape(1, -1)})\n",
    "    Q = Q[0]\n",
    "    return action, Q\n",
    "\n",
    "def reinforcement(state):\n",
    "    '''\n",
    "    The score is:\n",
    "       # sheep in pen * 10\n",
    "    - dis(sheep, pen)\n",
    "    '''\n",
    "    global game_map\n",
    "    saved_state, _ = game_map.get_state()\n",
    "    game_map.set_state(state)\n",
    "    score = game_map.get_score()\n",
    "    game_map.set_state(saved_state)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_game(sess, cur_state, num_samples, epsilon):\n",
    "    global game_map\n",
    "    num_sheep = len(game_map.sheep)\n",
    "    num_cols = 2 * (1 + num_sheep) + 1\n",
    "    X = np.zeros((num_samples, num_cols))\n",
    "    R = np.zeros((num_samples, 1))\n",
    "    Qn = np.zeros((num_samples, 1))\n",
    "    \n",
    "    action, _ = action_picker(sess, cur_state, epsilon)\n",
    "    for step in range(num_samples):\n",
    "        game_map.advance_moves(action, 20)\n",
    "        next_state, is_fin = game_map.get_state()\n",
    "        ref_next = reinforcement(next_state)\n",
    "        action_next, q_next = action_picker(sess, next_state, epsilon)\n",
    "        \n",
    "        cur_state = cur_state.reshape(1, -1)\n",
    "        cur_state = np.append(cur_state, action)\n",
    "        X[step, :] = cur_state\n",
    "        R[step, 0] = ref_next\n",
    "        Qn[step, 0] = q_next\n",
    "        \n",
    "        cur_state, action = next_state, action_next\n",
    "    return X, R, Qn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "[[140.          30.          43.82392462 158.37848863  41.68971423\n",
      "  243.2788932    1.        ]\n",
      " [140.          30.          43.82392462 158.37848863  34.61864642\n",
      "  236.20782539   1.        ]\n",
      " [140.          30.          43.82392462 166.87848863  30.70984084\n",
      "  229.17445372   1.        ]\n",
      " [140.          30.          43.82392462 176.87848863  30.13056459\n",
      "  222.64920508   4.        ]\n",
      " [140.          70.          43.82392462 186.87848863  30.59575859\n",
      "  216.79917082   1.        ]\n",
      " [140.          70.          43.82392462 187.87848863  30.17567241\n",
      "  211.69285784   1.        ]\n",
      " [140.          70.          43.82392462 187.87848863  30.21163437\n",
      "  207.32881311   1.        ]\n",
      " [140.          70.          43.82392462 187.87848863  30.0170922\n",
      "  203.67872407   1.        ]\n",
      " [140.          70.          43.82392462 187.87848863  30.0341844\n",
      "  203.51250188   5.        ]\n",
      " [100.          70.          42.82392462 187.87848863  30.0341844\n",
      "  203.51250188   2.        ]\n",
      " [100.          30.          32.82392462 187.87848863  30.0341844\n",
      "  203.51250188   3.        ]\n",
      " [140.          30.          30.69881412 187.87848863  30.0341844\n",
      "  203.51250188   1.        ]\n",
      " [140.          30.          30.68528056 187.87848863  30.0341844\n",
      "  203.51250188   4.        ]\n",
      " [140.          70.          30.90917969 187.87848863  30.0341844\n",
      "  199.51250188   5.        ]\n",
      " [100.          70.          30.         187.87848863  30.0341844\n",
      "  189.51250188   1.        ]\n",
      " [100.          70.          30.         187.87848863  30.0341844\n",
      "  184.51250188   1.        ]\n",
      " [100.          70.          30.         187.87848863  30.0341844\n",
      "  184.51250188   3.        ]\n",
      " [140.          70.          30.         187.87848863  30.0341844\n",
      "  184.51250188   5.        ]\n",
      " [100.          70.          31.41421356 189.29270219  30.0341844\n",
      "  184.51250188   1.        ]\n",
      " [100.          70.          38.48528137 196.36377     30.0341844\n",
      "  184.51250188   5.        ]\n",
      " [ 60.          70.          45.55634919 203.43483782  36.75169882\n",
      "  191.2300163    1.        ]\n",
      " [ 60.          70.          52.627417   210.50590563  43.82276663\n",
      "  198.30108411   3.        ]\n",
      " [100.          70.          52.98097039 210.85945902  50.89383445\n",
      "  205.37215192   4.        ]\n",
      " [100.         110.          52.98097039 210.85945902  57.96490226\n",
      "  212.44321973   4.        ]\n",
      " [100.         150.          51.16579589 213.24789287  61.85458085\n",
      "  220.39252805   1.        ]\n",
      " [100.         150.          45.05439044 221.16311387  57.0901915\n",
      "  229.18460369   5.        ]\n",
      " [ 60.         150.          38.94298498 229.07833486  52.32580215\n",
      "  237.97667934   5.        ]\n",
      " [ 30.         150.          32.83157953 236.99355585  47.56141281\n",
      "  246.76875498   2.        ]\n",
      " [ 30.         110.          30.00233039 244.74473434  42.79702346\n",
      "  255.56083063   5.        ]\n",
      " [ 30.         110.          30.30778707 251.18160201  38.03263411\n",
      "  264.35290627   3.        ]\n",
      " [ 70.         110.          30.23723068 255.7907906   33.26824477\n",
      "  273.14498192   4.        ]\n",
      " [ 70.         150.          30.01394283 256.32931241  30.42269954\n",
      "  281.85084264   2.        ]\n",
      " [ 70.         110.          30.01394283 256.32931241  30.63720292\n",
      "  288.44239033   5.        ]\n",
      " [ 30.         110.          30.01394283 256.32931241  30.68966756\n",
      "  291.13770696   1.        ]\n",
      " [ 30.         110.          30.02788566 256.32931241  30.05957784\n",
      "  291.78218412   3.        ]\n",
      " [ 70.         110.          30.09209667 261.85119852  30.05957784\n",
      "  291.78218412   4.        ]\n",
      " [ 70.         150.          30.27214471 266.96130367  30.05957784\n",
      "  291.78218412   3.        ]\n",
      " [110.         150.          30.04107831 270.55894979  30.05957784\n",
      "  291.78218412   2.        ]\n",
      " [110.         110.          30.04107831 270.55894979  31.05957784\n",
      "  291.78218412   3.        ]\n",
      " [150.         110.          30.04107831 270.55894979  41.05957784\n",
      "  291.78218412   5.        ]\n",
      " [110.         110.          30.04107831 270.55894979  51.05957784\n",
      "  291.78218412   5.        ]\n",
      " [ 70.         110.          30.04107831 270.55894979  61.05957784\n",
      "  291.78218412   4.        ]\n",
      " [ 70.         150.          33.57661222 274.09448369  71.05957784\n",
      "  291.78218412   3.        ]\n",
      " [110.         150.          40.64768003 281.1655515   81.05957784\n",
      "  291.78218412   2.        ]\n",
      " [110.         110.          47.71874784 288.23661932  91.05957784\n",
      "  291.78218412   1.        ]\n",
      " [110.         110.          54.08270887 294.60058035 101.05957784\n",
      "  291.78218412   4.        ]\n",
      " [110.         150.          54.08270887 294.60058035 104.55957784\n",
      "  291.78218412   1.        ]\n",
      " [110.         150.          54.08270887 294.60058035 104.55957784\n",
      "  291.78218412   2.        ]\n",
      " [110.         110.          54.08270887 294.60058035 104.55957784\n",
      "  291.78218412   1.        ]\n",
      " [110.         110.          54.08270887 294.60058035 104.55957784\n",
      "  291.78218412   4.        ]]\n",
      "[[-113.25046585]\n",
      " [-113.43388155]\n",
      " [-113.22916573]\n",
      " [-112.91669458]\n",
      " [-113.16356139]\n",
      " [-113.39214439]\n",
      " [-113.60412952]\n",
      " [-113.61163296]\n",
      " [-113.69393148]\n",
      " [-114.51999951]\n",
      " [-114.69625668]\n",
      " [-114.69737994]\n",
      " [-114.89506939]\n",
      " [-115.51980344]\n",
      " [-115.79895033]\n",
      " [-115.79895033]\n",
      " [-115.79895033]\n",
      " [-115.60272828]\n",
      " [-114.62201455]\n",
      " [-112.70927235]\n",
      " [-110.7487902 ]\n",
      " [-109.71934325]\n",
      " [-108.73955537]\n",
      " [-108.00137183]\n",
      " [-108.02603904]\n",
      " [-108.08748598]\n",
      " [-108.18565533]\n",
      " [-108.04084638]\n",
      " [-107.7128454 ]\n",
      " [-107.52782839]\n",
      " [-107.3975848 ]\n",
      " [-107.0982971 ]\n",
      " [-106.98101133]\n",
      " [-107.01039383]\n",
      " [-106.74887675]\n",
      " [-106.50001936]\n",
      " [-106.35906686]\n",
      " [-106.268051  ]\n",
      " [-105.35971723]\n",
      " [-104.45482587]\n",
      " [-103.55356412]\n",
      " [-102.1821691 ]\n",
      " [-100.34231202]\n",
      " [ -98.50876072]\n",
      " [ -96.77600454]\n",
      " [ -96.4675123 ]\n",
      " [ -96.4675123 ]\n",
      " [ -96.4675123 ]\n",
      " [ -96.4675123 ]\n",
      " [ -97.31390794]]\n",
      "[[-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]\n",
      " [-0.19523048]]\n"
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "    #train_op = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    number_updates = 1000\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        state, is_fin = game_map.get_state()\n",
    "        samples = 50\n",
    "        epsilon = .1\n",
    "        X, R, Qn = sample_game(sess, state, samples, epsilon)\n",
    "        print('-'*20)\n",
    "        print(X)\n",
    "        print(R)\n",
    "        print(Qn)\n",
    "run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I want to do this project is because it reminds me of Google's AlphaGo project.  AlphaGo was one of the first machine learning programs I learned about, and it fascinated me.  The program was able to beat the world's best Go player, not by being taught the best strategies, but by playing itself over and over again and improving each time.  I am really interested in the ability of machine learning to discover knowledge and strategies on its own. It seems that an algorithm teaching itself checkers is discovering knowledge, while algorithms trying to predict data sets are simply matching patterns.\n",
    "\n",
    "I'm currently planning on referencing this article:\n",
    "https://towardsdatascience.com/how-to-teach-an-ai-to-play-games-deep-reinforcement-learning-28f9b920440a\n",
    "\n",
    "I will convert the machine learning code used to play snake to code to play checkers with.  Then I will develop a process to duplicate the neural network to have two different players.  These players will face off in the checkers game, and the winner will move on to the next round.  In the next round I will mutate new opponents from the previous winner.  With enough iterations this \"survival of the fittest\" should produce a competent model of a checkers player.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Results\n",
    "\n",
    "At this point I think there are two possible results.\n",
    "\n",
    "The first is that I won't have enough computing power or time to train a competent checkers player.  This is not unlikely as there are a number of unknowns I will need to overcome. \n",
    "\n",
    "The second possibility is that I train a decent checkers player.  If I can get the evolutionary training process working, then there will probably be a number of basic moves that the machine learning model will be able to pick up. It seems unlikely though that the project will succeed at such a level that it could be classified as an expert checkers player.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline\n",
    "- April 19th, 2019.   Mechanics of checkers game will be set up\n",
    "- April 26th, 2019.   Game heuristics and loss and update functions are created\n",
    "- May 1st, 2019.   Genetic based training is working, time to tweak as required\n",
    "- May 8th, 2019.   Final results will be analyzed and report completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
